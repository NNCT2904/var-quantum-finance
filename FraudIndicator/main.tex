\section{Anomaly Detection and Fraud Indicator} \label{Sec: Anomaly Detection and Fraud Indicator}

Anomaly detection is used to find the data that is not follow the pattern of the given dataset.
Usage of fraud detection is diversed in many important application such as Fraud Detection, Data cleaning and surveillance.
The unusual data pattern, or anomalies, can be caused of unauthorised intrusion into a system, or faulty system.

Machine learning algorithms are indeed play an pivot role in anomaly detection for classical data in form of quantum state using quantum devices.
These algorithms typically provide measurement of how far the inspepcted data astray from the normal pattern.
Widely used methods can include: Quantum Support Vector Machine (QSVM) \cite{grossiMixedQuantumClassical2022,kyriienkoUnsupervisedQuantumMachine2022} and Principal Component Analysis (PCA) \cite{lloydQuantumPrincipalComponent2014a}.

\subsection{Quantum Support Vector Machine}
Michele et al. \cite{grossiMixedQuantumClassical2022} had presented the first end-to-end application of QSVM for financial industry based on real payment data.
In more details, the authors explored the approach to utilise QSVM for better improve the fraud detection.
The method is called Quantum Feature Important Selection; by utilising Quantum Support Vector Machine for pre-processing data, the author boosted the performance of Quantum Classifier in terms of prediction accuracy.
The experiment on an quantum emulator have also shown that this novelty approach also make the Quantum Classifier to learn different pattern such that classical models found difficult to detect.

\subsection{Quantum Kernel Component Analysis}
One Class Principal Component Analysis is widely used for anomalies detection.
The main idea of the algorithms is to calculate the difference between new datapoint $x^0$ and mean vector $\mu$ and the variance of the dataset.

The mean vector $\mu$ and covariance matrix $\Sigma$ of a dataset of $M$ datapoints are:
\begin{equation}
    \mu = \frac{1}{M} \sum^M_{i=1}x^i ,\;\;
    \Sigma = \frac{1}{M-1} \sum^M_{i=1} (x^i - \mu) (x^i-\mu)^T
    \label{eqn: mean vector, covariance matrix}
\end{equation}

The proximity measure $f(x^0)$ quantifies how anomalous the datapoint $x^0$ is compared to the overall trend of the whole training dataset:
\begin{equation}
    f(x^0) = \left| x^0 - \mu \right|^2 - \left( x^0 - \mu \right)^T \Sigma\left( x^0 - \mu \right)
\end{equation}
A larger $f(x^0)$ indicates that the datapoint is more anomalous than another datapoint with smaller $f(x^0)$.